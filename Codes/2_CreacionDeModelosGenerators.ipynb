{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KMh7VjQf6WM"
      },
      "source": [
        "<h1> Creación de Modelos\n",
        "\n",
        "<h3> Creación de modelos en base a máscaras y a puntos de interés\n",
        "\n",
        "Equipo de Reto 5\n",
        "\n",
        "Inteligencia artificial avanzada para la ciencia de datos II (Grupo 502)\n",
        "\n",
        "30 de noviembre de 2023\n",
        "\n",
        "Modificacion cambiando parametros de la GPU y utilizando generators para evitar problemas de RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSFXvm66tq5x",
        "outputId": "1656f099-c846-4888-f29f-09c5b2ee98d3"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKZZq8tEhVi5"
      },
      "source": [
        "### Preparar el entorno de trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uzsB6USHfzcI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-30 11:27:54.022499: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-30 11:27:54.066832: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "# Importar librerias y módulos necesarios\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Activation, MaxPooling2D, Conv2DTranspose, Concatenate, Input\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import shutil\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-30 11:27:56.714688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-30 11:27:56.763550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-30 11:27:56.763759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6RjnuTfbhkvl"
      },
      "outputs": [],
      "source": [
        "# Definir el directorio de trabajo actual\n",
        "os.chdir('/home/alanr/Documents/Corazon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MUWjCH_qhsxa"
      },
      "outputs": [],
      "source": [
        "# Definir el directorio con los conjuntos de datos\n",
        "data_directory = os.path.join(os.getcwd(), 'CompleteDatasets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SDPxR_WiblVe"
      },
      "outputs": [],
      "source": [
        "# Definir el directorio para guardar los mejores modelos y su historial de entrenamiento\n",
        "# Definir el directorio para guardar los mejores modelos y su historial de entrenamiento\n",
        "models_directory = os.path.join(os.getcwd(), 'Models')\n",
        "logs_directory = os.path.join(os.getcwd(), 'Logs')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gFnkG1m-llot"
      },
      "outputs": [],
      "source": [
        "# Definir dimensiones importantes de los datos\n",
        "img_height = 112\n",
        "img_width = 112\n",
        "img_channels = 1\n",
        "mask_channels = 1\n",
        "landmarks_channels = 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaKUAYE0itph"
      },
      "source": [
        "### Definir la arquitectura para un modelo U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NhRyeheaizBE"
      },
      "outputs": [],
      "source": [
        "# Definir un bloque convolucional\n",
        "def conv_block(input, num_filters):\n",
        "  x = Conv2D(num_filters, 3, padding='same')(input)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(num_filters, 3, padding='same')(x)\n",
        "  x = Activation('relu')(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M3DSTaKWjCVT"
      },
      "outputs": [],
      "source": [
        "# Definir un bloque codificador\n",
        "def encoder_block(input, num_filters):\n",
        "  x = conv_block(input, num_filters)\n",
        "  p = MaxPooling2D((2,2))(x)\n",
        "  return x, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "z8BksLd6jSnW"
      },
      "outputs": [],
      "source": [
        "# Definir un bloque decodificador\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "  x = Conv2DTranspose(num_filters, (2,2), strides=2, padding='same')(input)\n",
        "  x = Concatenate()([x, skip_features])\n",
        "  x = conv_block(x, num_filters)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WxClJRFKjehy"
      },
      "outputs": [],
      "source": [
        "# Definir la arquitectura para un modelo U-Net\n",
        "def build_unet(input_shape, num_clases):\n",
        "  inputs = Input(input_shape)\n",
        "\n",
        "  s1, p1 = encoder_block(inputs, 64)\n",
        "  s2, p2 = encoder_block(p1, 128)\n",
        "  s3, p3 = encoder_block(p2, 256)\n",
        "  s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "  b1 = conv_block(p4, 1024)\n",
        "\n",
        "  d1 = decoder_block(b1, s4, 512)\n",
        "  d2 = decoder_block(d1, s3, 256)\n",
        "  d3 = decoder_block(d2, s2, 128)\n",
        "  d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "  outputs = Conv2D(num_clases, 1, padding='same', activation='sigmoid')(d4)\n",
        "\n",
        "  model = Model(inputs, outputs, name='U-Net')\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l0mHvZYlMCi"
      },
      "source": [
        "### Crear y entrenar un modelo U-Net basado en máscaras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSlyk6n1asGN",
        "outputId": "24812628-00e3-4b16-fabf-71f08aa88090"
      },
      "outputs": [],
      "source": [
        "# # Cargar el conjunto de entrenamiento\n",
        "# train_input = np.load(os.path.join(data_directory, 'train_images.npy'))\n",
        "# train_output = np.load(os.path.join(data_directory, 'train_masks.npy'))\n",
        "# print('Dimensiones del conjunto de entrenamiento:', train_input.shape, train_output.shape)\n",
        "\n",
        "# # Cargar el conjunto de validación\n",
        "# val_input = np.load(os.path.join(data_directory, 'val_images.npy'))\n",
        "# val_output = np.load(os.path.join(data_directory, 'val_masks.npy'))\n",
        "# print('Dimensiones del conjunto de validación   :', val_input.shape, val_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eTJV6x2slQQH"
      },
      "outputs": [],
      "source": [
        "# # Crear y compilar el modelo basado en máscaras\n",
        "# mask_model = build_unet((img_height, img_height, img_channels), mask_channels)\n",
        "# mask_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3CZx1xjBmVEF"
      },
      "outputs": [],
      "source": [
        "# # Definir \"Callbacks\" para guardar los modelos mejor entrenados y el historial de entrenamiento\n",
        "# checkpoint = ModelCheckpoint(os.path.join(models_directory, 'masks_{epoch:02d}_{val_accuracy:.2f}.h5'), monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "# log_csv = CSVLogger(os.path.join(logs_directory, 'MaskModels.csv'), separator=',', append=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with tf.device('/cpu:0'):\n",
        "#     train_input = tf.convert_to_tensor(train_input, np.float32)\n",
        "#     train_output = tf.convert_to_tensor(train_output, np.float32)\n",
        "\n",
        "#     val_input = tf.convert_to_tensor(val_input, np.float32)\n",
        "#     val_output = tf.convert_to_tensor(val_output, np.float32)\n",
        "   \n",
        "# define generator function\n",
        "# def generator_images_and_masks():\n",
        "#     for idx in range(len(train_input)):\n",
        "#         # extract one image and the corresponding mask\n",
        "#          img = train_input[idx]\n",
        "#          mask = train_output[idx]\n",
        "\n",
        "#          # convert to TF tensors\n",
        "#          img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "#          mask_tensor = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
        "\n",
        "#          yield img_tensor, mask_tensor\n",
        "\n",
        "# def generator_images_and_masks_val():\n",
        "#     for idx in range(len(val_input)):\n",
        "#         # extract one image and the corresponding mask\n",
        "#          img = val_input[idx]\n",
        "#          mask = val_output[idx]\n",
        "\n",
        "#          # convert to TF tensors\n",
        "#          img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "#          mask_tensor = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
        "\n",
        "#          yield img_tensor, mask_tensor\n",
        "\n",
        "# # create dataset using generator function and specifying shapes and dtypes\n",
        "# dataset_train = tf.data.Dataset.from_generator(generator_images_and_masks, \n",
        "#                                          output_signature=(tf.TensorSpec(shape=(112, 112, 1), dtype=tf.float32),\n",
        "#                                                            tf.TensorSpec(shape=(112, 112, 1), dtype=tf.float32)))\n",
        "\n",
        "# dataset_val = tf.data.Dataset.from_generator(generator_images_and_masks_val, \n",
        "#                                          output_signature=(tf.TensorSpec(shape=(112, 112, 1), dtype=tf.float32),\n",
        "#                                                            tf.TensorSpec(shape=(112, 112, 1), dtype=tf.float32)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Explicitly set the batch size\n",
        "# batch_size = 16\n",
        "# dataset_train = dataset_train.batch(batch_size)\n",
        "# dataset_val = dataset_val.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NzDqDxEVmdLA"
      },
      "outputs": [],
      "source": [
        "# # Entrenar el modelo con los datos de entrenamiento y validación\n",
        "# mask_model.fit(dataset_train, validation_data=dataset_val,callbacks=[checkpoint, log_csv], epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mask_model.save(\"20Random_dataAug_mask_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCelMm14lQry"
      },
      "source": [
        "### Crear y entrenar un modelo U-Net basado en puntos de interés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ppIruJEobCB-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones del conjunto de entrenamiento: (15342, 112, 112, 1) (15342, 112, 112, 7)\n",
            "Dimensiones del conjunto de validación:    (2644, 112, 112, 1) (2644, 112, 112, 7)\n"
          ]
        }
      ],
      "source": [
        "# Cargar el conjunto de entrenamiento\n",
        "train_input = np.load(os.path.join(data_directory, 'train_images.npy'))\n",
        "train_input = train_input[:-1]\n",
        "train_output = np.load(os.path.join(data_directory, 'train_landmarks.npy'))\n",
        "print('Dimensiones del conjunto de entrenamiento:', train_input.shape, train_output.shape)\n",
        "\n",
        "# Cargar el conjunto de validación\n",
        "val_input = np.load(os.path.join(data_directory, 'val_images.npy'))\n",
        "val_output = np.load(os.path.join(data_directory, 'val_landmarks.npy'))\n",
        "print('Dimensiones del conjunto de validación:   ', val_input.shape, val_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uhHvTLpQk9DT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-30 11:27:58.905095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-30 11:27:58.905465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-30 11:27:58.905674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-30 11:27:59.022551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-30 11:27:59.022771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-30 11:27:59.022943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-30 11:27:59.023103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2284 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "# Crear y compilar el modelo basado en puntos de interés\n",
        "landmark_model = build_unet((img_height, img_height, img_channels), landmarks_channels)\n",
        "landmark_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z7FOaoPu5W9G"
      },
      "outputs": [],
      "source": [
        "# Definir \"Callbacks\" para guardar los modelos mejor entrenados y el historial de entrenamiento\n",
        "checkpoint = ModelCheckpoint(os.path.join(models_directory, 'landmarks_{epoch:02d}_{val_accuracy:.2f}.h5'), monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "log_csv = CSVLogger(os.path.join(logs_directory, 'LandmarkModels.csv'), separator=',', append=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# with tf.device('/cpu:0'):\n",
        "#     train_input = tf.convert_to_tensor(train_input, np.float32)\n",
        "#     train_output = tf.convert_to_tensor(train_output, np.float32)\n",
        "\n",
        "#     val_input = tf.convert_to_tensor(val_input, np.float32)\n",
        "#     val_output = tf.convert_to_tensor(val_output, np.float32)\n",
        "   \n",
        "# define generator function\n",
        "def generator_images_and_masks():\n",
        "    for idx in range(len(train_input)):\n",
        "        # extract one image and the corresponding mask\n",
        "         img = train_input[idx]\n",
        "         mask = train_output[idx]\n",
        "\n",
        "         # convert to TF tensors\n",
        "         img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "         mask_tensor = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
        "\n",
        "         yield img_tensor, mask_tensor\n",
        "\n",
        "def generator_images_and_masks_val():\n",
        "    for idx in range(len(val_input)):\n",
        "        # extract one image and the corresponding mask\n",
        "         img = val_input[idx]\n",
        "         mask = val_output[idx]\n",
        "\n",
        "         # convert to TF tensors\n",
        "         img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "         mask_tensor = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
        "\n",
        "         yield img_tensor, mask_tensor\n",
        "\n",
        "# create dataset using generator function and specifying shapes and dtypes\n",
        "dataset_train = tf.data.Dataset.from_generator(generator_images_and_masks, \n",
        "                                         output_signature=(tf.TensorSpec(shape=(112, 112, 1), dtype=tf.float32),\n",
        "                                                           tf.TensorSpec(shape=(112, 112, 7), dtype=tf.float32)))\n",
        "\n",
        "dataset_val = tf.data.Dataset.from_generator(generator_images_and_masks_val, \n",
        "                                         output_signature=(tf.TensorSpec(shape=(112, 112, 1), dtype=tf.float32),\n",
        "                                                           tf.TensorSpec(shape=(112, 112, 7), dtype=tf.float32)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explicitly set the batch size\n",
        "batch_size = 16\n",
        "dataset_train = dataset_train.batch(batch_size)\n",
        "dataset_val = dataset_val.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LolH1k-2nkGd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-30 11:28:01.220593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
            "2023-11-30 11:28:01.771925: W tensorflow/tsl/framework/bfc_allocator.cc:366] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
            "2023-11-30 11:28:02.890567: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0b6f0ef3a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-11-30 11:28:02.890617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
            "2023-11-30 11:28:02.894243: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-11-30 11:28:02.981394: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "2023-11-30 11:28:04.086955: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    958/Unknown - 212s 208ms/step - loss: 0.0212 - accuracy: 0.1390"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-30 11:31:34.174498: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2023-11-30 11:31:38.600514: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    959/Unknown - 220s 216ms/step - loss: 0.0212 - accuracy: 0.1391"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-30 11:31:53.551160: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10161103296151599331\n",
            "2023-11-30 11:31:53.551300: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16564640189053613321\n",
            "2023-11-30 11:31:53.551337: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8079921698153951001\n",
            "/usr/lib/python3/dist-packages/keras/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "959/959 [==============================] - 234s 230ms/step - loss: 0.0212 - accuracy: 0.1391 - val_loss: 0.0144 - val_accuracy: 0.2152\n",
            "Epoch 2/10\n",
            "959/959 [==============================] - 215s 224ms/step - loss: 0.0145 - accuracy: 0.2398 - val_loss: 0.0140 - val_accuracy: 0.1924\n",
            "Epoch 3/10\n",
            "959/959 [==============================] - 217s 227ms/step - loss: 0.0139 - accuracy: 0.2566 - val_loss: 0.0140 - val_accuracy: 0.2623\n",
            "Epoch 4/10\n",
            "959/959 [==============================] - 215s 224ms/step - loss: 0.0136 - accuracy: 0.2619 - val_loss: 0.0142 - val_accuracy: 0.3109\n",
            "Epoch 5/10\n",
            "959/959 [==============================] - 210s 219ms/step - loss: 0.0134 - accuracy: 0.2839 - val_loss: 0.0141 - val_accuracy: 0.2920\n",
            "Epoch 6/10\n",
            "959/959 [==============================] - 209s 218ms/step - loss: 0.0133 - accuracy: 0.2935 - val_loss: 0.0140 - val_accuracy: 0.2664\n",
            "Epoch 7/10\n",
            "959/959 [==============================] - 209s 218ms/step - loss: 0.0132 - accuracy: 0.2918 - val_loss: 0.0140 - val_accuracy: 0.2917\n",
            "Epoch 8/10\n",
            "959/959 [==============================] - 209s 218ms/step - loss: 0.0132 - accuracy: 0.2825 - val_loss: 0.0140 - val_accuracy: 0.2793\n",
            "Epoch 9/10\n",
            "959/959 [==============================] - 210s 219ms/step - loss: 0.0130 - accuracy: 0.3029 - val_loss: 0.0143 - val_accuracy: 0.2477\n",
            "Epoch 10/10\n",
            "959/959 [==============================] - 213s 222ms/step - loss: 0.0130 - accuracy: 0.3149 - val_loss: 0.0143 - val_accuracy: 0.3360\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0dfa23bdf0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Entrenar el modelo con los datos de entrenamiento y validación\n",
        "# Entrenar el modelo con los datos de entrenamiento y validación\n",
        "landmark_model.fit(dataset_train, validation_data=dataset_val,callbacks=[checkpoint, log_csv], epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "landmark_model.save(\"20Random_dataAug_landmark_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6aC7z-Mnzev"
      },
      "source": [
        "### Probar el funcionamiento de los mejores modelos con el conjunto de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MPEirNPdqcE",
        "outputId": "45c03666-b488-4dc4-a551-1f68f1d9ec50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones del conjunto de prueba: (2598, 112, 112, 1)\n"
          ]
        }
      ],
      "source": [
        "# Borrar los conjuntos de entrenamiento y validación tras entrenar los modelos\n",
        "train_input = train_output = val_input = val_output = 0\n",
        "\n",
        "# Cargar el conjunto de prueba\n",
        "test_images = np.load(os.path.join(data_directory, 'test_images.npy'))\n",
        "print('Dimensiones del conjunto de prueba:', test_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bq0i1n7SBUW8"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "No file or directory found at /home/alanr/Documents/Corazon/Models/masks_08_0.99.h5",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_8849/2926849334.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cargar los mejores modelos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmask_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'masks_08_0.99.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlandmark_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'landmarks_05_0.45.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     )\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /home/alanr/Documents/Corazon/Models/masks_08_0.99.h5"
          ]
        }
      ],
      "source": [
        "# Cargar los mejores modelos\n",
        "mask_model = load_model(os.path.join(models_directory, 'masks_08_0.99.h5'), compile=False)\n",
        "landmark_model = load_model(os.path.join(models_directory, 'landmarks_05_0.45.h5'), compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6oiEjD78ap2"
      },
      "outputs": [],
      "source": [
        "# Predecir con ambos modelos todos los datos en el conjunto de prueba\n",
        "mask_predictions = mask_model.predict(test_images)\n",
        "landmark_predictions = landmark_model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fdg-IxmciW_G"
      },
      "outputs": [],
      "source": [
        "# Mostrar predicciones para datos aleatorios del conjunto de prueba\n",
        "predictions = []\n",
        "\n",
        "# Para k número de predicciones\n",
        "for index in random.choices(range(0, len(test_images)), k=5):\n",
        "\n",
        "  # Seleccionar la imagen original y convertir a tres canales\n",
        "  frame = test_images[index]\n",
        "  frame = np.concatenate([frame, frame, frame], axis=2)\n",
        "\n",
        "  # Añadir la máscara sobre la imagen original\n",
        "  mask_prediction = np.squeeze(mask_predictions[index] > 0.5)\n",
        "  frame[:,:,0] = cv2.addWeighted(mask_prediction.astype(np.float32), 0.75, frame[:,:,0].astype(np.float32), 1, 0)\n",
        "\n",
        "  # Añadir los puntos de interés sobre la imagen original\n",
        "  landmarks_prediction = landmark_predictions[index]\n",
        "  background = np.zeros_like(frame[:,:,0])\n",
        "  for channel in range(landmarks_prediction.shape[2]):\n",
        "    landmark = (landmarks_prediction[:,:,channel] >= np.max(landmarks_prediction[:,:,channel]))\n",
        "    coord = np.unravel_index(np.argmax(landmark), landmark.shape)\n",
        "    coord = (coord[1], coord[0])\n",
        "    cv2.circle(background, coord, 2, 255, -1)\n",
        "  frame[:,:,2] = cv2.addWeighted(background.astype(np.float32), 0.75, frame[:,:,2].astype(np.float32), 1, 0)\n",
        "\n",
        "  # Añadir la imagen a una lista\n",
        "  predictions.append(frame * 255)\n",
        "\n",
        "# Mostrar en una sola línea las imagenes originales con sus predicciones\n",
        "divider = np.full((img_height, 1, 3), 255)\n",
        "cv2_imshow(np.concatenate((predictions[0], divider, predictions[1], divider, predictions[2], divider, predictions[3], divider, predictions[4]), axis=1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
